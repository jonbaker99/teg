{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from the parquet file\n",
    "def load_data():\n",
    "    return pd.read_parquet('../data/all-data.parquet')\n",
    "data = pd.read_parquet('../data/all-data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generalized aggregation function with dynamic level of aggregation\n",
    "def aggregate_data(data, aggregation_level, measures=['Sc', 'GrossVP', 'NetVP', 'Stableford']):\n",
    "    levels = {\n",
    "        'Pl': ['Pl', 'Player'],\n",
    "        'TEG': ['Pl', 'TEG', 'Player', 'TEGNum'],\n",
    "        'Round': ['Pl', 'TEG', 'Round', 'Player', 'TEGNum'],\n",
    "        'FrontBack': ['Pl', 'TEG', 'Round', 'FrontBack', 'Player', 'TEGNum']\n",
    "    }\n",
    "    \n",
    "    if aggregation_level not in levels:\n",
    "        raise ValueError(f\"Invalid aggregation level: {aggregation_level}. Choose from: {list(levels.keys())}\")\n",
    "    \n",
    "    group_columns = levels[aggregation_level]\n",
    "    return data.groupby(group_columns, as_index=False)[measures].sum().sort_values(by=group_columns)\n",
    "\n",
    "data = pd.read_parquet('../data/all-data.parquet')\n",
    "#print(data.head())\n",
    "\n",
    "teg_data = aggregate_data(data,'TEG')\n",
    "print(teg_data.head())\n",
    "print(teg_data.shape[0])\n",
    "\n",
    "rd_data = aggregate_data(data,'Round')\n",
    "print(rd_data.head())\n",
    "print(rd_data.shape[0])\n",
    "\n",
    "nine_data = aggregate_data(data,'FrontBack')\n",
    "print(nine_data.head())\n",
    "print(nine_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'format_vs_par' from 'utils' (c:\\Users\\JBA33\\OneDrive - Sky\\Documents\\python\\TEG\\streamlit\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m aggregate_data, format_vs_par\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the data from the Parquet file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m all_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/all-data.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'format_vs_par' from 'utils' (c:\\Users\\JBA33\\OneDrive - Sky\\Documents\\python\\TEG\\streamlit\\utils.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils import aggregate_data, format_vs_par\n",
    "\n",
    "# Load the data from the Parquet file\n",
    "all_data = pd.read_parquet('../data/all-data.parquet')\n",
    "\n",
    "# Filter out TEG 2 and TEG 50 (in place by reassigning to itself)\n",
    "all_data = all_data[~all_data['TEG'].isin(['TEG 2', 'TEG 50'])]\n",
    "\n",
    "# Aggregate the data by 'TEG'\n",
    "teg_data = aggregate_data(all_data, 'TEG')\n",
    "\n",
    "# Define the fields & number of rows to keep\n",
    "teg_fields = ['Player', 'TEG', 'GrossVP']\n",
    "n_keep = 10\n",
    "\n",
    "# Find the n lowest 'Sc' values and return the corresponding rows\n",
    "lowest_sc_rows = teg_data[teg_fields].nsmallest(n_keep, 'GrossVP').sort_values(by='GrossVP', ascending=True)\n",
    "lowest_sc_rows['Rank'] = lowest_sc_rows['GrossVP'].rank(method='min').astype(int).astype(str)\n",
    "lowest_sc_rows.loc[lowest_sc_rows.duplicated('Rank', keep=False), 'Rank'] += '='\n",
    "lowest_sc_rows = lowest_sc_rows[['Rank', 'Player', 'TEG', 'GrossVP']]\n",
    "lowest_sc_rows.rename(columns={'GrossVP': 'Gross'}, inplace=True)\n",
    "lowest_sc_rows['Gross'] = lowest_sc_rows['Gross'].apply(format_vs_par)\n",
    "\n",
    "# Print the rows with the lowest 'Sc' values\n",
    "print(lowest_sc_rows)\n",
    "\n",
    "\n",
    "def find_lowest_sc_rows(data, level_of_aggregation, fields_to_keep, top_n=10):\n",
    "    # Aggregate the data based on the provided level of aggregation\n",
    "    aggregated_data = aggregate_data(data, level_of_aggregation)\n",
    "    \n",
    "    # Find the n lowest 'GrossVP' values and return the corresponding rows\n",
    "    lowest_sc_rows = aggregated_data[fields_to_keep].nsmallest(top_n, 'GrossVP').sort_values(by='GrossVP', ascending=True)\n",
    "    \n",
    "    # Add ranking column\n",
    "    lowest_sc_rows['Rank'] = lowest_sc_rows['GrossVP'].rank(method='min').astype(int).astype(str)\n",
    "    lowest_sc_rows.loc[lowest_sc_rows.duplicated('Rank', keep=False), 'Rank'] += '='\n",
    "    \n",
    "    # Reorder and rename columns\n",
    "    lowest_sc_rows = lowest_sc_rows[['Rank'] + fields_to_keep]\n",
    "    lowest_sc_rows.rename(columns={'GrossVP': 'Gross'}, inplace=True)\n",
    "    \n",
    "    # Apply formatting to 'Gross' column\n",
    "    lowest_sc_rows['Gross'] = lowest_sc_rows['Gross'].apply(format_vs_par)\n",
    "    \n",
    "    return lowest_sc_rows\n",
    "\n",
    "\n",
    "rd_fields = ['Player', 'TEG', 'Round', 'GrossVP']\n",
    "lowest_rounds = find_lowest_sc_rows(all_data,'Round',rd_fields)\n",
    "print(lowest_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'format_vs_par' from 'utils' (c:\\Users\\JBA33\\OneDrive - Sky\\Documents\\python\\TEG\\streamlit\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m aggregate_data, format_vs_par\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the data from the Parquet file & exclude teg 2 and 50\u001b[39;00m\n\u001b[0;32m      5\u001b[0m all_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/all-data.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'format_vs_par' from 'utils' (c:\\Users\\JBA33\\OneDrive - Sky\\Documents\\python\\TEG\\streamlit\\utils.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils import aggregate_data, format_vs_par\n",
    "\n",
    "# Load the data from the Parquet file & exclude teg 2 and 50\n",
    "all_data = pd.read_parquet('../data/all-data.parquet')\n",
    "all_data = all_data[~all_data['TEG'].isin(['TEG 2', 'TEG 50'])]\n",
    "\n",
    "\n",
    "\n",
    "def find_lowest_sc_rows(data, level_of_aggregation, fields_to_keep, field='GrossVP', top_n=10):\n",
    "    # Aggregate the data based on the provided level of aggregation\n",
    "    aggregated_data = aggregate_data(data, level_of_aggregation)\n",
    "    \n",
    "    # Define properties for each field\n",
    "    field_properties = {\n",
    "        'GrossVP': {'new_name': 'Gross', 'ascending': True, 'formatter': format_vs_par, 'additional_field': 'Sc'},\n",
    "        'NetVP': {'new_name': 'Net', 'ascending': True, 'formatter': format_vs_par, 'additional_field': None},\n",
    "        'Sc': {'new_name': 'Gross Score', 'ascending': True, 'formatter': lambda x: int(x), 'additional_field': 'GrossVP'},\n",
    "        'Stableford': {'new_name': 'Stableford', 'ascending': False, 'formatter': lambda x: int(x), 'additional_field': None},\n",
    "    }\n",
    "    \n",
    "    # Get the properties for the selected field\n",
    "    properties = field_properties.get(field)\n",
    "    if not properties:\n",
    "        raise ValueError(f\"Invalid field: {field}\")\n",
    "    \n",
    "    # Append additional_field to fields_to_keep if it's not None\n",
    "    additional_field = properties['additional_field']\n",
    "    print(f\"\\nField is: {field};\\n additional_field is: {additional_field}\\nfields to keep: {fields_to_keep}\")\n",
    "\n",
    "    fields_to_keep += [additional_field] if additional_field else []\n",
    "\n",
    "    print(f\"\\nfields to keep: {fields_to_keep}\\n\")\n",
    "    \n",
    "    all_fields = fields_to_keep + [field]\n",
    "\n",
    "    print(f\"\\nall_fields: {all_fields}\")\n",
    "\n",
    "\n",
    "    # Sort the data based on the 'ascending' property\n",
    "    sorted_data = (aggregated_data[all_fields]\n",
    "                   .sort_values(by=field, ascending=properties['ascending'])\n",
    "                   .head(top_n))\n",
    "\n",
    "    # Add ranking column (ranking order follows the 'ascending' property)\n",
    "    sorted_data['Rank'] = sorted_data[field].rank(ascending=properties['ascending'], method='min').astype(int).astype(str)\n",
    "    sorted_data.loc[sorted_data.duplicated('Rank', keep=False), 'Rank'] += '='\n",
    "    \n",
    "    # Reorder and rename columns\n",
    "    sorted_data = sorted_data[['Rank'] + all_fields]\n",
    "    sorted_data.rename(columns={field: properties['new_name']}, inplace=True)\n",
    "    \n",
    "    # Apply formatting to the chosen field\n",
    "    sorted_data[properties['new_name']] = sorted_data[properties['new_name']].apply(properties['formatter'])\n",
    "    \n",
    "    return sorted_data\n",
    "\n",
    "n_keep = 10\n",
    "rd_fields = ['Player', 'TEG', 'Round']\n",
    "\n",
    "lowest_rounds_gross = find_lowest_sc_rows(all_data,'Round',rd_fields,'GrossVP' ,n_keep)\n",
    "print('\\nBest Gross')\n",
    "print(lowest_rounds_gross)\n",
    "\n",
    "print('rd_fields')\n",
    "print(rd_fields)\n",
    "\n",
    "lowest_rounds_sc = find_lowest_sc_rows(all_data,'Round',rd_fields,'Sc' ,n_keep)\n",
    "print('\\nBest Score')\n",
    "print(lowest_rounds_sc)\n",
    "\n",
    "lowest_rounds_net = find_lowest_sc_rows(all_data,'Round',rd_fields,'NetVP' ,n_keep)\n",
    "print('\\nBest Net')\n",
    "print(lowest_rounds_net)\n",
    "\n",
    "best_rounds_stableford = find_lowest_sc_rows(all_data,'Round',rd_fields,'Stableford' ,n_keep)\n",
    "print('\\n=======\\nBest Stableford\\n========')\n",
    "print(best_rounds_stableford)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in the DataFrame:\n",
      "- TEG\n",
      "- Round\n",
      "- Hole\n",
      "- PAR\n",
      "- SI\n",
      "- Pl\n",
      "- Sc\n",
      "- HC\n",
      "- HCStrokes\n",
      "- GrossVP\n",
      "- Net\n",
      "- NetVP\n",
      "- Stableford\n",
      "- TEGNum\n",
      "- HoleID\n",
      "- Player\n",
      "- FrontBack\n",
      "- Date\n",
      "- Course\n",
      "- Hole Order Ever\n",
      "- Sc Cum Round\n",
      "- Sc Cum TEG\n",
      "- Sc Cum Career\n",
      "- GrossVP Cum Round\n",
      "- GrossVP Cum TEG\n",
      "- GrossVP Cum Career\n",
      "- NetVP Cum Round\n",
      "- NetVP Cum TEG\n",
      "- NetVP Cum Career\n",
      "- Stableford Cum Round\n",
      "- Stableford Cum TEG\n",
      "- Stableford Cum Career\n",
      "- TEG Count\n",
      "- Career Count\n",
      "- Sc Round Avg\n",
      "- Sc TEG Avg\n",
      "- Sc Career Avg\n",
      "- GrossVP Round Avg\n",
      "- GrossVP TEG Avg\n",
      "- GrossVP Career Avg\n",
      "- NetVP Round Avg\n",
      "- NetVP TEG Avg\n",
      "- NetVP Career Avg\n",
      "- Stableford Round Avg\n",
      "- Stableford TEG Avg\n",
      "- Stableford Career Avg\n",
      "\n",
      "First few rows of the DataFrame:\n",
      "     TEG  Round  Hole  PAR  SI  Pl   Sc    HC  HCStrokes  GrossVP  ...  \\\n",
      "0  TEG 7      1     1    5   7  AB  8.0  36.0          2      3.0  ...   \n",
      "1  TEG 7      1     2    3  13  AB  4.0  36.0          2      1.0  ...   \n",
      "2  TEG 7      1     3    5  11  AB  6.0  36.0          2      1.0  ...   \n",
      "3  TEG 7      1     4    4  15  AB  5.0  36.0          2      1.0  ...   \n",
      "4  TEG 7      1     5    3  17  AB  8.0  36.0          2      5.0  ...   \n",
      "\n",
      "   Sc Career Avg  GrossVP Round Avg  GrossVP TEG Avg  GrossVP Career Avg  \\\n",
      "0           8.00           3.000000         3.000000            3.000000   \n",
      "1           6.00           2.000000         2.000000            2.000000   \n",
      "2           6.00           1.666667         1.666667            1.666667   \n",
      "3           5.75           1.500000         1.500000            1.500000   \n",
      "4           6.20           2.200000         2.200000            2.200000   \n",
      "\n",
      "  NetVP Round Avg NetVP TEG Avg NetVP Career Avg Stableford Round Avg  \\\n",
      "0        1.000000      1.000000         1.000000             1.000000   \n",
      "1        0.000000      0.000000         0.000000             2.000000   \n",
      "2       -0.333333     -0.333333        -0.333333             2.333333   \n",
      "3       -0.500000     -0.500000        -0.500000             2.500000   \n",
      "4        0.200000      0.200000         0.200000             2.000000   \n",
      "\n",
      "  Stableford TEG Avg  Stableford Career Avg  \n",
      "0           1.000000               1.000000  \n",
      "1           2.000000               2.000000  \n",
      "2           2.333333               2.333333  \n",
      "3           2.500000               2.500000  \n",
      "4           2.000000               2.000000  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "df = data\n",
    "# Print the columns\n",
    "print(\"\\nColumns in the DataFrame:\")\n",
    "for col in df.columns:\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "# Print the first few rows\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
