{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from the parquet file\n",
    "def load_data():\n",
    "    return pd.read_parquet('../data/all-data.parquet')\n",
    "data = pd.read_parquet('../data/all-data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generalized aggregation function with dynamic level of aggregation\n",
    "def aggregate_data(data, aggregation_level, measures=['Sc', 'GrossVP', 'NetVP', 'Stableford']):\n",
    "    levels = {\n",
    "        'Pl': ['Pl', 'Player'],\n",
    "        'TEG': ['Pl', 'TEG', 'Player', 'TEGNum'],\n",
    "        'Round': ['Pl', 'TEG', 'Round', 'Player', 'TEGNum'],\n",
    "        'FrontBack': ['Pl', 'TEG', 'Round', 'FrontBack', 'Player', 'TEGNum']\n",
    "    }\n",
    "    \n",
    "    if aggregation_level not in levels:\n",
    "        raise ValueError(f\"Invalid aggregation level: {aggregation_level}. Choose from: {list(levels.keys())}\")\n",
    "    \n",
    "    group_columns = levels[aggregation_level]\n",
    "    return data.groupby(group_columns, as_index=False)[measures].sum().sort_values(by=group_columns)\n",
    "\n",
    "data = pd.read_parquet('../data/all-data.parquet')\n",
    "#print(data.head())\n",
    "\n",
    "teg_data = aggregate_data(data,'TEG')\n",
    "print(teg_data.head())\n",
    "print(teg_data.shape[0])\n",
    "\n",
    "rd_data = aggregate_data(data,'Round')\n",
    "print(rd_data.head())\n",
    "print(rd_data.shape[0])\n",
    "\n",
    "nine_data = aggregate_data(data,'FrontBack')\n",
    "print(nine_data.head())\n",
    "print(nine_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'format_vs_par' from 'utils' (c:\\Users\\JBA33\\OneDrive - Sky\\Documents\\python\\TEG\\streamlit\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m aggregate_data, format_vs_par\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the data from the Parquet file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m all_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/all-data.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'format_vs_par' from 'utils' (c:\\Users\\JBA33\\OneDrive - Sky\\Documents\\python\\TEG\\streamlit\\utils.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils import aggregate_data, format_vs_par\n",
    "\n",
    "# Load the data from the Parquet file\n",
    "all_data = pd.read_parquet('../data/all-data.parquet')\n",
    "\n",
    "# Filter out TEG 2 and TEG 50 (in place by reassigning to itself)\n",
    "all_data = all_data[~all_data['TEG'].isin(['TEG 2', 'TEG 50'])]\n",
    "\n",
    "# Aggregate the data by 'TEG'\n",
    "teg_data = aggregate_data(all_data, 'TEG')\n",
    "\n",
    "# Define the fields & number of rows to keep\n",
    "teg_fields = ['Player', 'TEG', 'GrossVP']\n",
    "n_keep = 10\n",
    "\n",
    "# Find the n lowest 'Sc' values and return the corresponding rows\n",
    "lowest_sc_rows = teg_data[teg_fields].nsmallest(n_keep, 'GrossVP').sort_values(by='GrossVP', ascending=True)\n",
    "lowest_sc_rows['Rank'] = lowest_sc_rows['GrossVP'].rank(method='min').astype(int).astype(str)\n",
    "lowest_sc_rows.loc[lowest_sc_rows.duplicated('Rank', keep=False), 'Rank'] += '='\n",
    "lowest_sc_rows = lowest_sc_rows[['Rank', 'Player', 'TEG', 'GrossVP']]\n",
    "lowest_sc_rows.rename(columns={'GrossVP': 'Gross'}, inplace=True)\n",
    "lowest_sc_rows['Gross'] = lowest_sc_rows['Gross'].apply(format_vs_par)\n",
    "\n",
    "# Print the rows with the lowest 'Sc' values\n",
    "print(lowest_sc_rows)\n",
    "\n",
    "\n",
    "def find_lowest_sc_rows(data, level_of_aggregation, fields_to_keep, top_n=10):\n",
    "    # Aggregate the data based on the provided level of aggregation\n",
    "    aggregated_data = aggregate_data(data, level_of_aggregation)\n",
    "    \n",
    "    # Find the n lowest 'GrossVP' values and return the corresponding rows\n",
    "    lowest_sc_rows = aggregated_data[fields_to_keep].nsmallest(top_n, 'GrossVP').sort_values(by='GrossVP', ascending=True)\n",
    "    \n",
    "    # Add ranking column\n",
    "    lowest_sc_rows['Rank'] = lowest_sc_rows['GrossVP'].rank(method='min').astype(int).astype(str)\n",
    "    lowest_sc_rows.loc[lowest_sc_rows.duplicated('Rank', keep=False), 'Rank'] += '='\n",
    "    \n",
    "    # Reorder and rename columns\n",
    "    lowest_sc_rows = lowest_sc_rows[['Rank'] + fields_to_keep]\n",
    "    lowest_sc_rows.rename(columns={'GrossVP': 'Gross'}, inplace=True)\n",
    "    \n",
    "    # Apply formatting to 'Gross' column\n",
    "    lowest_sc_rows['Gross'] = lowest_sc_rows['Gross'].apply(format_vs_par)\n",
    "    \n",
    "    return lowest_sc_rows\n",
    "\n",
    "\n",
    "rd_fields = ['Player', 'TEG', 'Round', 'GrossVP']\n",
    "lowest_rounds = find_lowest_sc_rows(all_data,'Round',rd_fields)\n",
    "print(lowest_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'format_vs_par' from 'utils' (c:\\Users\\JBA33\\OneDrive - Sky\\Documents\\python\\TEG\\streamlit\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m aggregate_data, format_vs_par\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the data from the Parquet file & exclude teg 2 and 50\u001b[39;00m\n\u001b[0;32m      5\u001b[0m all_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/all-data.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'format_vs_par' from 'utils' (c:\\Users\\JBA33\\OneDrive - Sky\\Documents\\python\\TEG\\streamlit\\utils.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils import aggregate_data, format_vs_par\n",
    "\n",
    "# Load the data from the Parquet file & exclude teg 2 and 50\n",
    "all_data = pd.read_parquet('../data/all-data.parquet')\n",
    "all_data = all_data[~all_data['TEG'].isin(['TEG 2', 'TEG 50'])]\n",
    "\n",
    "\n",
    "\n",
    "def find_lowest_sc_rows(data, level_of_aggregation, fields_to_keep, field='GrossVP', top_n=10):\n",
    "    # Aggregate the data based on the provided level of aggregation\n",
    "    aggregated_data = aggregate_data(data, level_of_aggregation)\n",
    "    \n",
    "    # Define properties for each field\n",
    "    field_properties = {\n",
    "        'GrossVP': {'new_name': 'Gross', 'ascending': True, 'formatter': format_vs_par, 'additional_field': 'Sc'},\n",
    "        'NetVP': {'new_name': 'Net', 'ascending': True, 'formatter': format_vs_par, 'additional_field': None},\n",
    "        'Sc': {'new_name': 'Gross Score', 'ascending': True, 'formatter': lambda x: int(x), 'additional_field': 'GrossVP'},\n",
    "        'Stableford': {'new_name': 'Stableford', 'ascending': False, 'formatter': lambda x: int(x), 'additional_field': None},\n",
    "    }\n",
    "    \n",
    "    # Get the properties for the selected field\n",
    "    properties = field_properties.get(field)\n",
    "    if not properties:\n",
    "        raise ValueError(f\"Invalid field: {field}\")\n",
    "    \n",
    "    # Append additional_field to fields_to_keep if it's not None\n",
    "    additional_field = properties['additional_field']\n",
    "    print(f\"\\nField is: {field};\\n additional_field is: {additional_field}\\nfields to keep: {fields_to_keep}\")\n",
    "\n",
    "    fields_to_keep += [additional_field] if additional_field else []\n",
    "\n",
    "    print(f\"\\nfields to keep: {fields_to_keep}\\n\")\n",
    "    \n",
    "    all_fields = fields_to_keep + [field]\n",
    "\n",
    "    print(f\"\\nall_fields: {all_fields}\")\n",
    "\n",
    "\n",
    "    # Sort the data based on the 'ascending' property\n",
    "    sorted_data = (aggregated_data[all_fields]\n",
    "                   .sort_values(by=field, ascending=properties['ascending'])\n",
    "                   .head(top_n))\n",
    "\n",
    "    # Add ranking column (ranking order follows the 'ascending' property)\n",
    "    sorted_data['Rank'] = sorted_data[field].rank(ascending=properties['ascending'], method='min').astype(int).astype(str)\n",
    "    sorted_data.loc[sorted_data.duplicated('Rank', keep=False), 'Rank'] += '='\n",
    "    \n",
    "    # Reorder and rename columns\n",
    "    sorted_data = sorted_data[['Rank'] + all_fields]\n",
    "    sorted_data.rename(columns={field: properties['new_name']}, inplace=True)\n",
    "    \n",
    "    # Apply formatting to the chosen field\n",
    "    sorted_data[properties['new_name']] = sorted_data[properties['new_name']].apply(properties['formatter'])\n",
    "    \n",
    "    return sorted_data\n",
    "\n",
    "n_keep = 10\n",
    "rd_fields = ['Player', 'TEG', 'Round']\n",
    "\n",
    "lowest_rounds_gross = find_lowest_sc_rows(all_data,'Round',rd_fields,'GrossVP' ,n_keep)\n",
    "print('\\nBest Gross')\n",
    "print(lowest_rounds_gross)\n",
    "\n",
    "print('rd_fields')\n",
    "print(rd_fields)\n",
    "\n",
    "lowest_rounds_sc = find_lowest_sc_rows(all_data,'Round',rd_fields,'Sc' ,n_keep)\n",
    "print('\\nBest Score')\n",
    "print(lowest_rounds_sc)\n",
    "\n",
    "lowest_rounds_net = find_lowest_sc_rows(all_data,'Round',rd_fields,'NetVP' ,n_keep)\n",
    "print('\\nBest Net')\n",
    "print(lowest_rounds_net)\n",
    "\n",
    "best_rounds_stableford = find_lowest_sc_rows(all_data,'Round',rd_fields,'Stableford' ,n_keep)\n",
    "print('\\n=======\\nBest Stableford\\n========')\n",
    "print(best_rounds_stableford)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in the DataFrame:\n",
      "- TEG\n",
      "- Round\n",
      "- Hole\n",
      "- PAR\n",
      "- SI\n",
      "- Pl\n",
      "- Sc\n",
      "- HC\n",
      "- HCStrokes\n",
      "- GrossVP\n",
      "- Net\n",
      "- NetVP\n",
      "- Stableford\n",
      "- TEGNum\n",
      "- HoleID\n",
      "- Player\n",
      "- FrontBack\n",
      "- Date\n",
      "- Course\n",
      "- Hole Order Ever\n",
      "- Sc Cum Round\n",
      "- Sc Cum TEG\n",
      "- Sc Cum Career\n",
      "- GrossVP Cum Round\n",
      "- GrossVP Cum TEG\n",
      "- GrossVP Cum Career\n",
      "- NetVP Cum Round\n",
      "- NetVP Cum TEG\n",
      "- NetVP Cum Career\n",
      "- Stableford Cum Round\n",
      "- Stableford Cum TEG\n",
      "- Stableford Cum Career\n",
      "- TEG Count\n",
      "- Career Count\n",
      "- Sc Round Avg\n",
      "- Sc TEG Avg\n",
      "- Sc Career Avg\n",
      "- GrossVP Round Avg\n",
      "- GrossVP TEG Avg\n",
      "- GrossVP Career Avg\n",
      "- NetVP Round Avg\n",
      "- NetVP TEG Avg\n",
      "- NetVP Career Avg\n",
      "- Stableford Round Avg\n",
      "- Stableford TEG Avg\n",
      "- Stableford Career Avg\n",
      "\n",
      "First few rows of the DataFrame:\n",
      "     TEG  Round  Hole  PAR  SI  Pl   Sc    HC  HCStrokes  GrossVP  ...  \\\n",
      "0  TEG 7      1     1    5   7  AB  8.0  36.0          2      3.0  ...   \n",
      "1  TEG 7      1     2    3  13  AB  4.0  36.0          2      1.0  ...   \n",
      "2  TEG 7      1     3    5  11  AB  6.0  36.0          2      1.0  ...   \n",
      "3  TEG 7      1     4    4  15  AB  5.0  36.0          2      1.0  ...   \n",
      "4  TEG 7      1     5    3  17  AB  8.0  36.0          2      5.0  ...   \n",
      "\n",
      "   Sc Career Avg  GrossVP Round Avg  GrossVP TEG Avg  GrossVP Career Avg  \\\n",
      "0           8.00           3.000000         3.000000            3.000000   \n",
      "1           6.00           2.000000         2.000000            2.000000   \n",
      "2           6.00           1.666667         1.666667            1.666667   \n",
      "3           5.75           1.500000         1.500000            1.500000   \n",
      "4           6.20           2.200000         2.200000            2.200000   \n",
      "\n",
      "  NetVP Round Avg NetVP TEG Avg NetVP Career Avg Stableford Round Avg  \\\n",
      "0        1.000000      1.000000         1.000000             1.000000   \n",
      "1        0.000000      0.000000         0.000000             2.000000   \n",
      "2       -0.333333     -0.333333        -0.333333             2.333333   \n",
      "3       -0.500000     -0.500000        -0.500000             2.500000   \n",
      "4        0.200000      0.200000         0.200000             2.000000   \n",
      "\n",
      "  Stableford TEG Avg  Stableford Career Avg  \n",
      "0           1.000000               1.000000  \n",
      "1           2.000000               2.000000  \n",
      "2           2.333333               2.333333  \n",
      "3           2.500000               2.500000  \n",
      "4           2.000000               2.000000  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "df = data\n",
    "# Print the columns\n",
    "print(\"\\nColumns in the DataFrame:\")\n",
    "for col in df.columns:\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "# Print the first few rows\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pl     TEG      Player  TEGNum     Sc  GrossVP  NetVP  Stableford\n",
      "0  AB  TEG 10  Alex BAKER      10  376.0     90.0  -38.0       184.0\n",
      "1  AB  TEG 11  Alex BAKER      11  394.0    106.0   10.0       137.0\n",
      "2  AB  TEG 12  Alex BAKER      12  392.0    104.0    4.0       143.0\n",
      "3  AB  TEG 13  Alex BAKER      13  390.0    103.0    3.0       141.0\n",
      "4  AB  TEG 14  Alex BAKER      14  389.0    102.0   -2.0       152.0\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "all_data = data\n",
    "teg_data = utils.aggregate_data(all_data,'TEG')\n",
    "print(teg_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped DataFrame:\n",
      "       TEG  GrossVP  Stableford\n",
      "0   TEG 10    537.0       932.0\n",
      "1   TEG 11    471.0       676.0\n",
      "2   TEG 12    518.0       916.0\n",
      "3   TEG 13    407.0       727.0\n",
      "4   TEG 14    321.0       568.0\n",
      "5   TEG 15    623.0       798.0\n",
      "6   TEG 16    494.0       699.0\n",
      "7    TEG 2    444.0       451.0\n",
      "8    TEG 3    473.0       721.0\n",
      "9    TEG 4    553.0       622.0\n",
      "10   TEG 5    460.0       723.0\n",
      "11  TEG 50    369.0       340.0\n",
      "12   TEG 6    517.0       684.0\n",
      "13   TEG 7    504.0      1000.0\n",
      "14   TEG 8    675.0       754.0\n",
      "15   TEG 9    599.0       894.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Lowest GrossVP': {'TEG': 'TEG 14', 'GrossVP Sum': 321.0},\n",
       " 'Highest Stableford': {'TEG': 'TEG 7', 'Stableford Sum': 1000.0},\n",
       " 'Lowest Stableford': {'TEG': 'TEG 50', 'Stableford Sum': 340.0}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_teg_statistics(df):\n",
    "    \"\"\"\n",
    "    Computes the following statistics for each TEG:\n",
    "    - Sum of GrossVP\n",
    "    - Sum of Stableford\n",
    "    \n",
    "    Identifies:\n",
    "    - TEG with the lowest sum of GrossVP\n",
    "    - TEG with the highest sum of Stableford\n",
    "    - TEG with the lowest sum of Stableford\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing TEG data with 'TEG', 'GrossVP', and 'Stableford' columns.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing the identified TEGs and their corresponding sums.\n",
    "    \"\"\"\n",
    "    # Validate required columns\n",
    "    required_columns = {'TEG', 'GrossVP', 'Stableford'}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        missing = required_columns - set(df.columns)\n",
    "        raise ValueError(f\"Missing columns in DataFrame: {missing}\")\n",
    "    \n",
    "    # Group by 'TEG' and calculate sum of 'GrossVP' and 'Stableford'\n",
    "    grouped = df.groupby('TEG').agg({'GrossVP': 'sum', 'Stableford': 'sum'}).reset_index()\n",
    "    \n",
    "    # Debug: Show grouped DataFrame\n",
    "    print(\"Grouped DataFrame:\")\n",
    "    print(grouped)\n",
    "    \n",
    "    # Identify TEG with the lowest sum of GrossVP\n",
    "    lowest_grossvp_row = grouped.loc[grouped['GrossVP'].idxmin()]\n",
    "    lowest_grossvp_teg = lowest_grossvp_row['TEG']\n",
    "    lowest_grossvp_sum = lowest_grossvp_row['GrossVP']\n",
    "    \n",
    "    # Identify TEG with the highest sum of Stableford\n",
    "    highest_stableford_row = grouped.loc[grouped['Stableford'].idxmax()]\n",
    "    highest_stableford_teg = highest_stableford_row['TEG']\n",
    "    highest_stableford_sum = highest_stableford_row['Stableford']\n",
    "    \n",
    "    # Identify TEG with the lowest sum of Stableford\n",
    "    lowest_stableford_row = grouped.loc[grouped['Stableford'].idxmin()]\n",
    "    lowest_stableford_teg = lowest_stableford_row['TEG']\n",
    "    lowest_stableford_sum = lowest_stableford_row['Stableford']\n",
    "    \n",
    "    # Compile results into a dictionary\n",
    "    results = {\n",
    "        'Lowest GrossVP': {\n",
    "            'TEG': lowest_grossvp_teg,\n",
    "            'GrossVP Sum': lowest_grossvp_sum\n",
    "        },\n",
    "        'Highest Stableford': {\n",
    "            'TEG': highest_stableford_teg,\n",
    "            'Stableford Sum': highest_stableford_sum\n",
    "        },\n",
    "        'Lowest Stableford': {\n",
    "            'TEG': lowest_stableford_teg,\n",
    "            'Stableford Sum': lowest_stableford_sum\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "compute_teg_statistics(teg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEG</th>\n",
       "      <th>Year</th>\n",
       "      <th>Best Net</th>\n",
       "      <th>Best Gross</th>\n",
       "      <th>Worst Net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEG 2</td>\n",
       "      <td>2009</td>\n",
       "      <td>David MULLIN</td>\n",
       "      <td>David MULLIN</td>\n",
       "      <td>Henry MELLER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEG 3</td>\n",
       "      <td>2010</td>\n",
       "      <td>Jon BAKER</td>\n",
       "      <td>David MULLIN</td>\n",
       "      <td>Stuart NEUMANN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEG 4</td>\n",
       "      <td>2011</td>\n",
       "      <td>David MULLIN</td>\n",
       "      <td>David MULLIN</td>\n",
       "      <td>Gregg WILLIAMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEG 5</td>\n",
       "      <td>2012</td>\n",
       "      <td>Gregg WILLIAMS</td>\n",
       "      <td>Stuart NEUMANN</td>\n",
       "      <td>David MULLIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEG 6</td>\n",
       "      <td>2013</td>\n",
       "      <td>Gregg WILLIAMS</td>\n",
       "      <td>David MULLIN</td>\n",
       "      <td>Henry MELLER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TEG 7</td>\n",
       "      <td>2014</td>\n",
       "      <td>Henry MELLER</td>\n",
       "      <td>David MULLIN</td>\n",
       "      <td>Alex BAKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TEG 8</td>\n",
       "      <td>2015</td>\n",
       "      <td>Gregg WILLIAMS</td>\n",
       "      <td>David MULLIN</td>\n",
       "      <td>Stuart NEUMANN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TEG 9</td>\n",
       "      <td>2016</td>\n",
       "      <td>John PATTERSON</td>\n",
       "      <td>David MULLIN</td>\n",
       "      <td>Stuart NEUMANN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEG 10</td>\n",
       "      <td>2017</td>\n",
       "      <td>Alex BAKER</td>\n",
       "      <td>David MULLIN</td>\n",
       "      <td>John PATTERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEG 11</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jon BAKER</td>\n",
       "      <td>Jon BAKER</td>\n",
       "      <td>David MULLIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TEG 12</td>\n",
       "      <td>2019</td>\n",
       "      <td>John PATTERSON</td>\n",
       "      <td>Jon BAKER</td>\n",
       "      <td>David MULLIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TEG 13</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jon BAKER</td>\n",
       "      <td>Jon BAKER</td>\n",
       "      <td>David MULLIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TEG 14</td>\n",
       "      <td>2021</td>\n",
       "      <td>David MULLIN</td>\n",
       "      <td>David MULLIN</td>\n",
       "      <td>Jon BAKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TEG 15</td>\n",
       "      <td>2022</td>\n",
       "      <td>Gregg WILLIAMS</td>\n",
       "      <td>Gregg WILLIAMS</td>\n",
       "      <td>Alex BAKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TEG 16</td>\n",
       "      <td>2023</td>\n",
       "      <td>Stuart NEUMANN</td>\n",
       "      <td>Gregg WILLIAMS</td>\n",
       "      <td>Alex BAKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TEG 50</td>\n",
       "      <td>0</td>\n",
       "      <td>Jon BAKER</td>\n",
       "      <td>Jon BAKER</td>\n",
       "      <td>Alex BAKER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TEG  Year        Best Net      Best Gross       Worst Net\n",
       "0    TEG 2  2009    David MULLIN    David MULLIN    Henry MELLER\n",
       "1    TEG 3  2010       Jon BAKER    David MULLIN  Stuart NEUMANN\n",
       "2    TEG 4  2011    David MULLIN    David MULLIN  Gregg WILLIAMS\n",
       "3    TEG 5  2012  Gregg WILLIAMS  Stuart NEUMANN    David MULLIN\n",
       "4    TEG 6  2013  Gregg WILLIAMS    David MULLIN    Henry MELLER\n",
       "5    TEG 7  2014    Henry MELLER    David MULLIN      Alex BAKER\n",
       "6    TEG 8  2015  Gregg WILLIAMS    David MULLIN  Stuart NEUMANN\n",
       "7    TEG 9  2016  John PATTERSON    David MULLIN  Stuart NEUMANN\n",
       "8   TEG 10  2017      Alex BAKER    David MULLIN  John PATTERSON\n",
       "9   TEG 11  2018       Jon BAKER       Jon BAKER    David MULLIN\n",
       "10  TEG 12  2019  John PATTERSON       Jon BAKER    David MULLIN\n",
       "11  TEG 13  2020       Jon BAKER       Jon BAKER    David MULLIN\n",
       "12  TEG 14  2021    David MULLIN    David MULLIN       Jon BAKER\n",
       "13  TEG 15  2022  Gregg WILLIAMS  Gregg WILLIAMS      Alex BAKER\n",
       "14  TEG 16  2023  Stuart NEUMANN  Gregg WILLIAMS      Alex BAKER\n",
       "15  TEG 50     0       Jon BAKER       Jon BAKER      Alex BAKER"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#COMPUTE BEST & WORST SCORES BY TEG\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "all_data['Year'] = pd.to_datetime(all_data['Date'],format = '%d/%m/%Y').dt.year\n",
    "# print(all_data['Year'])\n",
    "teg_yr = all_data[['TEG', 'Year']].drop_duplicates()\n",
    "teg_yr['Year'] = teg_yr['Year'].fillna(0).astype(int)\n",
    "#print(teg_yr)\n",
    "\n",
    "\n",
    "def get_teg_summary(df):\n",
    "    # Group by 'TEG' and 'Player', and calculate the sum for each player in each TEG\n",
    "    grouped = df.groupby(['TEGNum','Player']).agg({\n",
    "        'GrossVP': 'sum',\n",
    "        'Stableford': 'sum'\n",
    "    }).sort_values(by=\"TEGNum\").reset_index()\n",
    "\n",
    "    # Initialize a list to store the results for each TEG\n",
    "    results = []\n",
    "\n",
    "    # Get unique TEG values\n",
    "    for teg in df['TEGNum'].unique():\n",
    "        # Filter for the current TEG\n",
    "        teg_data = grouped[grouped['TEGNum'] == teg]\n",
    "        \n",
    "        # Get the player with the lowest sum of GrossVP\n",
    "        lowest_grossvp = teg_data.loc[teg_data['GrossVP'].idxmin()]\n",
    "        \n",
    "        # Get the player with the highest sum of Stableford\n",
    "        highest_stableford = teg_data.loc[teg_data['Stableford'].idxmax()]\n",
    "        \n",
    "        # Get the player with the lowest sum of Stableford\n",
    "        lowest_stableford = teg_data.loc[teg_data['Stableford'].idxmin()]\n",
    "        \n",
    "        # Append the result for this TEG\n",
    "        results.append({\n",
    "            'TEGNum': teg,\n",
    "            'TEG': \"TEG \"+ str(teg),\n",
    "            'Best Gross': lowest_grossvp['Player'],\n",
    "            #'Lowest GrossVP Sum': lowest_grossvp['GrossVP'],\n",
    "            'Best Net': highest_stableford['Player'],\n",
    "            #'Highest Stableford Sum': highest_stableford['Stableford'],\n",
    "            'Worst Net': lowest_stableford['Player'],\n",
    "            #'Lowest Stableford Sum': lowest_stableford['Stableford']\n",
    "        })\n",
    "        \n",
    "    #results_sorted = results.drop(columns=['TEGNum'])\n",
    "    # Convert results to a DataFrame\n",
    "    result_df = pd.DataFrame(results).sort_values(by='TEGNum').drop(columns=['TEGNum'])\n",
    "    #teg_yr['Year'] = teg_yr['Year'].astype(str)\n",
    "    results_with_year = pd.merge(result_df,teg_yr,on='TEG',how='left')\n",
    "    results_with_year = results_with_year[['TEG', 'Year', 'Best Net', 'Best Gross', 'Worst Net']]\n",
    "    \n",
    "    \n",
    "    #Replace to correct to history\n",
    "    results_with_year.loc[results_with_year['TEG'] == 'TEG 5', 'Best Net'] = 'Gregg WILLIAMS'\n",
    "    results_with_year.loc[results_with_year['TEG'] == 'TEG 5', 'Best Gross'] = 'Stuart NEUMANN'\n",
    "\n",
    "    return results_with_year\n",
    "\n",
    "get_teg_summary(teg_data)\n",
    "# Example usage:\n",
    "# Assuming df is your DataFrame with the structure you provided\n",
    "# result = get_teg_summary(df)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "nothing to repeat at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m winners \u001b[38;5;241m=\u001b[39m get_teg_winners(all_data)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#winners.to_clipboard(index=False)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#winners\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#REMOVE ASTERISKS\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m winner_df \u001b[38;5;241m=\u001b[39m \u001b[43mwinners\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m winner_df\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# # Melt the DataFrame to have players and competitions in long format\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# melted = pd.melt(df, id_vars=['TEG', 'Year'], value_vars=['TEG Trophy', 'Green Jacket', 'HMM Wooden Spoon'],\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#                  var_name='Competition', value_name='Player')\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# print(melted)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:8127\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   8124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replace_columnwise(mapping, inplace, regex)\n\u001b[0;32m   8126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(value):  \u001b[38;5;66;03m# NA -> 0\u001b[39;00m\n\u001b[1;32m-> 8127\u001b[0m     regex \u001b[38;5;241m=\u001b[39m \u001b[43mshould_use_regex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_replace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m regex:\n\u001b[0;32m   8129\u001b[0m         new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreplace_regex(\n\u001b[0;32m   8130\u001b[0m             to_replace\u001b[38;5;241m=\u001b[39mto_replace,\n\u001b[0;32m   8131\u001b[0m             value\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[0;32m   8132\u001b[0m             inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   8133\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\array_algos\\replace.py:38\u001b[0m, in \u001b[0;36mshould_use_regex\u001b[1;34m(regex, to_replace)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_re(to_replace):\n\u001b[0;32m     36\u001b[0m     regex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m regex \u001b[38;5;241m=\u001b[39m regex \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mis_re_compilable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_replace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Don't use regex if the pattern is empty.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m regex \u001b[38;5;241m=\u001b[39m regex \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39mcompile(to_replace)\u001b[38;5;241m.\u001b[39mpattern \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\inference.py:188\u001b[0m, in \u001b[0;36mis_re_compilable\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03mCheck if the object can be compiled into a regex pattern instance.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03mFalse\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\re\\__init__.py:228\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(pattern, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\re\\__init__.py:307\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe re.TEMPLATE/re.T flag is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is an undocumented flag \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout an obvious purpose. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    306\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m--> 307\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43m_compiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m&\u001b[39m DEBUG:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\re\\_compiler.py:745\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[0;32m    744\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m--> 745\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\re\\_parser.py:979\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    976\u001b[0m state\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m flags\n\u001b[0;32m    977\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m--> 979\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSRE_FLAG_VERBOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m fix_flags(\u001b[38;5;28mstr\u001b[39m, p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags)\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\re\\_parser.py:460\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    458\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m     itemsappend(\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\re\\_parser.py:687\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    685\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m item \u001b[38;5;129;01mor\u001b[39;00m item[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m AT:\n\u001b[1;32m--> 687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnothing to repeat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    688\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m here \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(this))\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m _REPEATCODES:\n\u001b[0;32m    690\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiple repeat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    691\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m here \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(this))\n",
      "\u001b[1;31merror\u001b[0m: nothing to repeat at position 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils import load_all_data, get_teg_winners\n",
    "\n",
    "all_data = load_all_data()\n",
    "winners = get_teg_winners(all_data)\n",
    "#winners.to_clipboard(index=False)\n",
    "#winners\n",
    "\n",
    "#REMOVE ASTERISKS\n",
    "winner_df = winners.replace('*', '', regex=True)\n",
    "\n",
    "\n",
    "winner_df\n",
    "\n",
    "# # Melt the DataFrame to have players and competitions in long format\n",
    "# melted = pd.melt(df, id_vars=['TEG', 'Year'], value_vars=['TEG Trophy', 'Green Jacket', 'HMM Wooden Spoon'],\n",
    "#                  var_name='Competition', value_name='Player')\n",
    "# print(melted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
