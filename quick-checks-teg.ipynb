{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'data/teg-all-data-long.csv')\n",
    "print(df['TEGNum'].dtype)\n",
    "teg_df = df.groupby(['Pl', 'TEG', 'TEGNum'], as_index=False)[['Sc', 'Stableford', 'GrossVP', 'NetVP']].sum().sort_values(by=['Pl','TEGNum'])\n",
    "teg_df.to_clipboard(index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20faa69dca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html, dash_table\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {'Player': ['Stuart Neumann', 'Gregg Williams', 'David Mullin', 'Jon Baker', 'Alex Baker'],\n",
    "        'R1': [39, 34, 33, 34, 29],\n",
    "        'R2': [35, 30, 34, 32, 32],\n",
    "        'R3': [39, 37, 30, 33, 33],\n",
    "        'R4': [43, 42, 45, 32, 33],\n",
    "        'Total': [156, 143, 142, 131, 127]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add a Rank column based on the Total column (descending order)\n",
    "df['Rank'] = df['Total'].rank(ascending=False, method='min').astype(int)\n",
    "\n",
    "# Reorder the columns, making 'Rank' the first column\n",
    "df = df[['Rank', 'Player', 'R1', 'R2', 'R3', 'R4', 'Total']]\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# List of columns to make grey\n",
    "grey_columns = ['R1', 'R2', 'R3', 'R4']\n",
    "\n",
    "# Create a conditional list for grey columns dynamically\n",
    "style_cell_conditional = [\n",
    "    {\n",
    "        'if': {'column_id': 'Player'},\n",
    "        'textAlign': 'left',\n",
    "        'paddingLeft': '15px'  # Add left padding to the first column\n",
    "    },\n",
    "    {\n",
    "        'if': {'column_id': 'Total'},\n",
    "        'fontWeight': 'bold',    # Bold the last column (Total)\n",
    "    },\n",
    "    {\n",
    "        'if': {'column_id': 'Rank'},\n",
    "        'fontSize': '12px',      # Smaller font for the Rank column\n",
    "        'width': '60px',         # Narrow column width\n",
    "        'fontWeight': 'normal'   # No bold for Rank column\n",
    "    }\n",
    "]\n",
    "\n",
    "# Append the conditional styling for grey color to the grey columns\n",
    "style_cell_conditional += [{'if': {'column_id': col}, 'color': 'grey'} for col in grey_columns]\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dash_table.DataTable(\n",
    "        data=df.to_dict('records'),\n",
    "        # Columns with a blank header for Rank\n",
    "        columns=[{'name': '' if col == 'Rank' else col, 'id': col} for col in df.columns],\n",
    "        style_cell={\n",
    "            'fontFamily': 'Arial',\n",
    "            'fontSize': '14px',\n",
    "            'textAlign': 'center',\n",
    "            'height': '50px'  # Increase the row height\n",
    "        },\n",
    "        style_cell_conditional=style_cell_conditional,\n",
    "        # Header styling with thick black border below for all headers\n",
    "        style_header={\n",
    "            'backgroundColor': 'white',\n",
    "            'fontWeight': 'bold',\n",
    "            'borderBottom': '3px solid black',  # Thick black border for all headers\n",
    "            'borderTop': 'none',\n",
    "            'borderLeft': 'none',\n",
    "            'borderRight': 'none'\n",
    "        },\n",
    "        # Add faint grey horizontal border below each row\n",
    "        style_data={\n",
    "            'borderBottom': '1px solid lightgrey',  # Faint grey horizontal border\n",
    "            'borderTop': 'none',\n",
    "            'borderLeft': 'none',\n",
    "            'borderRight': 'none'\n",
    "        },\n",
    "        style_as_list_view=True,\n",
    "    )\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "           Player  R1  R2  R3  R4  Total\n",
      "0  Stuart Neumann  39  35  39  43    156\n",
      "1  Gregg Williams  34  30  37  42    143\n",
      "2    David Mullin  33  34  30  45    142\n",
      "3       Jon Baker  34  32  33  32    131\n",
      "4      Alex Baker  29  32  33  33    127\n",
      "\n",
      "DataFrame after reset_index(drop=True):\n",
      "           Player  R1  R2  R3  R4  Total\n",
      "0  Stuart Neumann  39  35  39  43    156\n",
      "1  Gregg Williams  34  30  37  42    143\n",
      "2    David Mullin  33  34  30  45    142\n",
      "3       Jon Baker  34  32  33  32    131\n",
      "4      Alex Baker  29  32  33  33    127\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Index(...) must be called with a collection of some kind, None was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_reset)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Method 2: Set index to None\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOriginal DataFrame after setting index to None:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:6307\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6305\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6306\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6309\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:812\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, labels: AnyArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    808\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;124;03m    This is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03m    directly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 812\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[43mensure_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7648\u001b[0m, in \u001b[0;36mensure_index\u001b[1;34m(index_like, copy)\u001b[0m\n\u001b[0;32m   7646\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Index(index_like, copy\u001b[38;5;241m=\u001b[39mcopy, tupleize_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   7647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 7648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:526\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[1;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[0;32m    523\u001b[0m         data \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39m_dtype_obj)\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(data):\n\u001b[1;32m--> 526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_scalar_data_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(np\u001b[38;5;241m.\u001b[39masarray(data), dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\JBA33\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5285\u001b[0m, in \u001b[0;36mIndex._raise_scalar_data_error\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m   5280\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   5281\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   5282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_scalar_data_error\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data):\n\u001b[0;32m   5283\u001b[0m     \u001b[38;5;66;03m# We return the TypeError so that we can raise it from the constructor\u001b[39;00m\n\u001b[0;32m   5284\u001b[0m     \u001b[38;5;66;03m#  in order to keep mypy happy\u001b[39;00m\n\u001b[1;32m-> 5285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   5286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(...) must be called with a collection of some \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(data)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28misinstance\u001b[39m(data,\u001b[38;5;250m \u001b[39mnp\u001b[38;5;241m.\u001b[39mgeneric)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas passed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5289\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Index(...) must be called with a collection of some kind, None was passed"
     ]
    }
   ],
   "source": [
    "data = {'Player': ['Stuart Neumann', 'Gregg Williams', 'David Mullin', 'Jon Baker', 'Alex Baker'],\n",
    "        'R1': [39, 34, 33, 34, 29],\n",
    "        'R2': [35, 30, 34, 32, 32],\n",
    "        'R3': [39, 37, 30, 33, 33],\n",
    "        'R4': [43, 42, 45, 32, 33],\n",
    "        'Total': [156, 143, 142, 131, 127]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Method 1: Reset index and drop\n",
    "df_reset = df.reset_index(drop=True)\n",
    "print(\"\\nDataFrame after reset_index(drop=True):\")\n",
    "print(df_reset)\n",
    "\n",
    "# Method 2: Set index to None\n",
    "df.index = None\n",
    "print(\"\\nOriginal DataFrame after setting index to None:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame\n",
    "data = {'Player': ['Stuart Neumann', 'Gregg Williams', 'David Mullin', 'Jon Baker', 'Alex Baker'],\n",
    "        'R1': [39, 34, 33, 34, 29],\n",
    "        'R2': [35, 30, 34, 32, 32],\n",
    "        'R3': [39, 37, 30, 33, 33],\n",
    "        'R4': [43, 42, 45, 32, 33],\n",
    "        'Total': [156, 143, 142, 131, 127]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['Rank'] = df['Total'].rank(ascending=False, method='min').astype(int)\n",
    "df = df[['Rank', 'Player', 'R1', 'R2', 'R3', 'R4', 'Total']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank Pl  1  2  3  4  Total\n",
      "   1 GW 18 22 15 11     66\n",
      "   2 DM 23 22 26 11     82\n",
      "   3 JB 21 23 25 24     93\n",
      "   4 SN 26 30 26 23    105\n",
      "   5 AB 42 34 34 38    148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JBA33\\AppData\\Local\\Temp\\ipykernel_28316\\2986125347.py:26: FutureWarning:\n",
      "\n",
      "Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'data/teg-all-data-long.csv')\n",
    "measures = ['Sc', 'GrossVP', 'NetVP', 'Stableford']\n",
    "group_rd = ['Pl', 'TEGNum', 'TEG', 'Round']\n",
    "round_df = df.groupby(group_rd, as_index=False)[measures].sum().sort_values(by=['Pl','TEGNum','Round'])\n",
    "\n",
    "chosen_teg = 'TEG 16'\n",
    "leaderboard_df = round_df[round_df['TEG' = chosen_teg]]\n",
    "\n",
    "def create_leaderboard(leaderboard_df):\n",
    "    # Create pivot table and calculate total in one step\n",
    "    jacketboard_pivot = leaderboard_df.pivot_table(\n",
    "        index='Pl', \n",
    "        columns='Round', \n",
    "        values='GrossVP', \n",
    "        aggfunc='sum', \n",
    "        fill_value=0\n",
    "    ).assign(Total=lambda x: x.sum(axis=1)).sort_values('Total', ascending=True)\n",
    "\n",
    "    # Reset index and calculate rank\n",
    "    jacketboard_pivot = jacketboard_pivot.reset_index()\n",
    "    jacketboard_pivot['Rank'] = jacketboard_pivot['Total'].rank(method='min', ascending=True).astype(int)\n",
    "\n",
    "    # Handle tied ranks\n",
    "    duplicated_scores = jacketboard_pivot['Total'].duplicated(keep=False)\n",
    "    jacketboard_pivot.loc[duplicated_scores, 'Rank'] = jacketboard_pivot.loc[duplicated_scores, 'Rank'].astype(str) + '='\n",
    "\n",
    "    # Reorder columns\n",
    "    columns = ['Rank', 'Pl'] + [col for col in jacketboard_pivot.columns if col not in ['Rank', 'Pl']]\n",
    "    jacketboard_pivot = jacketboard_pivot[columns]\n",
    "\n",
    "    return jacketboard_pivot\n",
    "\n",
    "\n",
    "\n",
    "chosen_teg = 'TEG 16'\n",
    "leaderboard_df = round_df[round_df['TEG'] == chosen_teg]\n",
    "\n",
    "result = create_leaderboard(leaderboard_df)\n",
    "print(result.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TEGNum  Round  Hole  SI  Pl  Sc  PAR     TEG    HC       HoleID FrontBack  \\\n",
      "0      50      1     1   8  AB   5    4  TEG 50  38.0  T50|R01|H01     Front   \n",
      "1      50      1     2  14  AB   8    5  TEG 50  38.0  T50|R01|H02     Front   \n",
      "2      50      1     3  18  AB   3    3  TEG 50  38.0  T50|R01|H03     Front   \n",
      "3      50      1     4  12  AB   4    4  TEG 50  38.0  T50|R01|H04     Front   \n",
      "4      50      1     5   2  AB   6    4  TEG 50  38.0  T50|R01|H05     Front   \n",
      "\n",
      "       Player  HCStrokes  GrossVP  NetVP  Stableford  \n",
      "0  Alex BAKER          2        1     -1           3  \n",
      "1  Alex BAKER          2        3      1           1  \n",
      "2  Alex BAKER          2        0     -2           4  \n",
      "3  Alex BAKER          2        0     -2           4  \n",
      "4  Alex BAKER          3        2     -1           3  \n",
      "Unique combinations of TRH have been copied to the clipboard.\n"
     ]
    }
   ],
   "source": [
    "import gspread\n",
    "import pandas as pd\n",
    "from google.oauth2.service_account import Credentials\n",
    "from math import floor\n",
    "\n",
    "# Import the player name lookup function from player_utils.py\n",
    "from player_utils import get_player_name\n",
    "\n",
    "# Google Sheets API setup\n",
    "SCOPE = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "CREDS_PATH = r\"credentials\\maps-1489139675490-41bee944be4e.json\"  # Path to your service account JSON file\n",
    "\n",
    "# Authorize the client\n",
    "creds = Credentials.from_service_account_file(CREDS_PATH, scopes=SCOPE)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Specify the Google Sheet and worksheet\n",
    "SHEET_NAME = \"TEG Round Input\"  # Name of your Google Sheet\n",
    "WORKSHEET_NAME = \"Scores\"  # Name of the specific worksheet (tab)\n",
    "\n",
    "# Open the Google Sheet and select the worksheet\n",
    "sheet = client.open(SHEET_NAME).worksheet(WORKSHEET_NAME)\n",
    "\n",
    "# Fetch all records (rows) from the worksheet\n",
    "data = sheet.get_all_records()\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define non-player columns (fixed columns)\n",
    "id_vars = ['TEGNum', 'Round', 'Hole', 'Par', 'SI']  # Columns to keep\n",
    "\n",
    "# Convert player columns to a standard list for cleaner printing\n",
    "player_columns = list(df.columns[5:])\n",
    "\n",
    "# Melt the DataFrame to convert wide to long format\n",
    "long_df = pd.melt(df, id_vars=id_vars, value_vars=player_columns, var_name='Pl', value_name='Score')\n",
    "\n",
    "# Convert the 'Score' column to numeric, if necessary\n",
    "long_df['Score'] = pd.to_numeric(long_df['Score'], errors='coerce')\n",
    "\n",
    "# Exclude rows where Score is either NaN (blank) or 0\n",
    "long_df = long_df.dropna(subset=['Score'])  # Remove rows where Score is NaN\n",
    "long_df = long_df[long_df['Score'] != 0]    # Remove rows where Score is 0\n",
    "\n",
    "# Ensure there are 18 holes per round per player\n",
    "long_df = long_df.groupby(['TEGNum', 'Round', 'Pl']).filter(lambda x: len(x) == 18)\n",
    "\n",
    "# Load the handicaps.csv file\n",
    "hc_lookup = pd.read_csv('data/handicaps.csv')\n",
    "\n",
    "# Melt the wide-format handicaps table to long format\n",
    "hc_long = pd.melt(hc_lookup, id_vars='TEG', var_name='Pl', value_name='HC')\n",
    "\n",
    "# Remove rows where 'HC' is missing or zero\n",
    "hc_long = hc_long.dropna(subset=['HC'])\n",
    "hc_long = hc_long[hc_long['HC'] != 0]\n",
    "\n",
    "# Define the transformations for the long format DataFrame\n",
    "def apply_transformations(long_df):\n",
    "    # Score becomes Sc\n",
    "    long_df['Sc'] = long_df['Score']\n",
    "    long_df.drop('Score', axis=1, inplace=True)\n",
    "\n",
    "    # Par becomes PAR\n",
    "    long_df['PAR'] = long_df['Par']\n",
    "    long_df.drop('Par', axis=1, inplace=True)\n",
    "\n",
    "    # TEG = 'TEG ' + TEGNum\n",
    "    long_df['TEG'] = 'TEG ' + long_df['TEGNum'].astype(str)\n",
    "\n",
    "    # Merge the handicaps with the long_df data\n",
    "    long_df = long_df.merge(hc_long, on=['TEG', 'Pl'], how='left')\n",
    "\n",
    "    # Handle NaN values by creating a new DataFrame without using inplace\n",
    "    long_df['HC'] = long_df['HC'].fillna(0)\n",
    "\n",
    "    # HoleID = combination of TEG, Round, Hole in format 'T00|R00|H00'\n",
    "    long_df['HoleID'] = long_df.apply(lambda row: f\"T{int(row['TEGNum']):02}|R{int(row['Round']):02}|H{int(row['Hole']):02}\", axis=1)\n",
    "\n",
    "    # FrontBack = 'Front' if Hole < 10, otherwise 'Back'\n",
    "    long_df['FrontBack'] = long_df['Hole'].apply(lambda hole: 'Front' if hole < 10 else 'Back')\n",
    "\n",
    "    # Player = get player name from initials (Pl)\n",
    "    long_df['Player'] = long_df['Pl'].apply(get_player_name)\n",
    "\n",
    "    # HCStrokes = Excel formula equivalent =1*(MOD(HC,18)>=SI)+FLOOR(HC/18,1)\n",
    "    long_df['HCStrokes'] = long_df.apply(lambda row: 1 * (row['HC'] % 18 >= row['SI']) + floor(row['HC'] / 18), axis=1)\n",
    "\n",
    "    # GrossVP = Sc - PAR\n",
    "    long_df['GrossVP'] = long_df['Sc'] - long_df['PAR']\n",
    "\n",
    "    # NetVP = GrossVP - HCStrokes\n",
    "    long_df['NetVP'] = long_df['GrossVP'] - long_df['HCStrokes']\n",
    "\n",
    "    # Stableford = max(0, 2 - NetVP)\n",
    "    long_df['Stableford'] = long_df['NetVP'].apply(lambda x: max(0, 2 - x))\n",
    "\n",
    "    return long_df\n",
    "\n",
    "# Apply transformations\n",
    "transformed_df = apply_transformations(long_df)\n",
    "\n",
    "# Display the transformed data for verification\n",
    "print(transformed_df.head())\n",
    "\n",
    "# After applying transformations, check combinations of HC, SI, and HCStrokes\n",
    "def check_hc_strokes_combinations(transformed_df):\n",
    "    # Select the relevant columns for the check\n",
    "    hc_si_strokes_df = transformed_df[['HC', 'SI', 'HCStrokes']]\n",
    "    \n",
    "    # Drop duplicates to get unique combinations\n",
    "    unique_combinations = hc_si_strokes_df.drop_duplicates()\n",
    "    \n",
    "    # Copy the unique combinations to clipboard\n",
    "    unique_combinations.to_clipboard(index=False)\n",
    "    \n",
    "    print(\"Unique combinations of HC, SI, and HCStrokes have been copied to the clipboard.\")\n",
    "\n",
    "# Check the combinations in the transformed data and send to clipboard\n",
    "#check_hc_strokes_combinations(transformed_df)\n",
    "\n",
    "# After applying transformations, check combinations of HC, SI, and HCStrokes\n",
    "def check_TRH_combinations(transformed_df):\n",
    "    # Select the relevant columns for the check\n",
    "    trh_df = transformed_df[['TEG', 'Round', 'Hole','HoleID']]\n",
    "    \n",
    "    # Drop duplicates to get unique combinations\n",
    "    unique_combinations = trh_df.drop_duplicates()\n",
    "    \n",
    "    # Copy the unique combinations to clipboard\n",
    "    unique_combinations.to_clipboard(index=False)\n",
    "    \n",
    "    print(\"Unique combinations of TRH have been copied to the clipboard.\")\n",
    "\n",
    "check_TRH_combinations(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TEGNum  Round  Hole  SI  Pl  Sc  PAR     TEG    HC       HoleID FrontBack  \\\n",
      "0      50      1     1   8  AB   5    4  TEG 50  38.0  T50|R01|H01     Front   \n",
      "1      50      1     2  14  AB   8    5  TEG 50  38.0  T50|R01|H02     Front   \n",
      "2      50      1     3  18  AB   3    3  TEG 50  38.0  T50|R01|H03     Front   \n",
      "3      50      1     4  12  AB   4    4  TEG 50  38.0  T50|R01|H04     Front   \n",
      "4      50      1     5   2  AB   6    4  TEG 50  38.0  T50|R01|H05     Front   \n",
      "\n",
      "       Player  HCStrokes  GrossVP  NetVP  Stableford  \n",
      "0  Alex BAKER          2        1     -1           3  \n",
      "1  Alex BAKER          2        3      1           1  \n",
      "2  Alex BAKER          2        0     -2           4  \n",
      "3  Alex BAKER          2        0     -2           4  \n",
      "4  Alex BAKER          3        2     -1           3  \n"
     ]
    }
   ],
   "source": [
    "import gspread\n",
    "import pandas as pd\n",
    "from google.oauth2.service_account import Credentials\n",
    "from data_utilities import process_round_for_all_scores  # Import the renamed function\n",
    "\n",
    "# Google Sheets API setup\n",
    "SCOPE = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "CREDS_PATH = r\"credentials\\maps-1489139675490-41bee944be4e.json\"  # Path to your service account JSON file\n",
    "\n",
    "# Authorize the client\n",
    "creds = Credentials.from_service_account_file(CREDS_PATH, scopes=SCOPE)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Specify the Google Sheet and worksheet\n",
    "SHEET_NAME = \"TEG Round Input\"  # Name of your Google Sheet\n",
    "WORKSHEET_NAME = \"Scores\"  # Name of the specific worksheet (tab)\n",
    "\n",
    "# Open the Google Sheet and select the worksheet\n",
    "sheet = client.open(SHEET_NAME).worksheet(WORKSHEET_NAME)\n",
    "\n",
    "# Fetch all records (rows) from the worksheet\n",
    "data = sheet.get_all_records()\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define non-player columns (fixed columns)\n",
    "id_vars = ['TEGNum', 'Round', 'Hole', 'Par', 'SI']  # Columns to keep\n",
    "\n",
    "# Convert player columns to a standard list for cleaner printing\n",
    "player_columns = list(df.columns[5:])\n",
    "\n",
    "# Melt the DataFrame to convert wide to long format\n",
    "long_df = pd.melt(df, id_vars=id_vars, value_vars=player_columns, var_name='Pl', value_name='Score')\n",
    "\n",
    "# Convert the 'Score' column to numeric, if necessary\n",
    "long_df['Score'] = pd.to_numeric(long_df['Score'], errors='coerce')\n",
    "\n",
    "# Exclude rows where Score is either NaN (blank) or 0\n",
    "long_df = long_df.dropna(subset=['Score'])  # Remove rows where Score is NaN\n",
    "long_df = long_df[long_df['Score'] != 0]    # Remove rows where Score is 0\n",
    "\n",
    "# Ensure there are 18 holes per round per player\n",
    "long_df = long_df.groupby(['TEGNum', 'Round', 'Pl']).filter(lambda x: len(x) == 18)\n",
    "\n",
    "# Load the handicaps.csv file\n",
    "hc_lookup = pd.read_csv('data/handicaps.csv')\n",
    "\n",
    "# Melt the wide-format handicaps table to long format\n",
    "hc_long = pd.melt(hc_lookup, id_vars='TEG', var_name='Pl', value_name='HC')\n",
    "\n",
    "# Remove rows where 'HC' is missing or zero\n",
    "hc_long = hc_long.dropna(subset=['HC'])\n",
    "hc_long = hc_long[hc_long['HC'] != 0]\n",
    "\n",
    "# Apply transformations from data_utilities.py\n",
    "transformed_df = process_round_for_all_scores(long_df, hc_long)\n",
    "\n",
    "# Display the transformed data for verification\n",
    "print(transformed_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
